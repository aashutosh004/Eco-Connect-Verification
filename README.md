# Eco-Connect Verification (Face + Liveness + Task)
Server-side Python service for verifying a userâ€™s identity (face embedding), checking liveness (anti-spoof), and validating a task/action in a submitted image using YOLO. Ships with a minimal HTML test page.

> **Stack**: Flask API Â· InsightFace (buffalo_l) Â· MiniFASNetV2 (PyTorch) Â· Ultralytics YOLO (pt/ONNX) Â· NumPy Â· onnxruntime (CPU/GPU)

---

## âœ¨ Features
- **Enrollment with multiâ€‘shot support**: send multiple `images[]` and the service builds a **centroid embedding** per user (stores up to 5 latest shots).
- **Verification pipeline (parallel)**: face **match** + **liveness** + **YOLO task** run concurrently for faster responses.
- **Productionâ€‘leaning defaults**: request size caps, allowed extensions, atomic DB writes, unified error JSON, CORS allowâ€‘list.
- **Simple test UI** at `/` for webcam capture or file upload (no external frontend required for quick tests).
- **CPUâ€‘first**: runs on CPU; **autoâ€‘uses GPU** if `onnxruntime-gpu` + CUDA are available.
- **Modelâ€‘agnostic**: swap InsightFace packs (`buffalo_l`/`antelopev2`), point YOLO to your custom `.pt`/`.onnx`, adjust liveness hyperâ€‘params.

---

## ðŸ“ Directory Layout
```
.
â”œâ”€ app.py                      # Flask app (API + test page)
â”œâ”€ config.py                   # All tunables (env-driven)
â”œâ”€ requirements.txt
â”œâ”€ templates/
â”‚  â””â”€ index.html               # Test UI (webcam + upload)
â”œâ”€ models/
â”‚  â”œâ”€ best.pt                  # YOLO model (your custom labels)
â”‚  â””â”€ 2.7_80x80_MiniFASNetV2.pth  # Liveness model
â”œâ”€ modules/
â”‚  â”œâ”€ dbio.py                  # atomic .npy read/write
â”‚  â”œâ”€ errors.py                # unified JSON errors
â”‚  â”œâ”€ face_enroll.py           # enrollment pipeline
â”‚  â”œâ”€ face_verify.py           # verification (centroid + shots)
â”‚  â”œâ”€ facekit.py               # InsightFace loader
â”‚  â”œâ”€ liveness_check.py        # MiniFASNetV2 inference
â”‚  â”œâ”€ task_detection.py        # YOLO task detection
â”‚  â””â”€ third_party/MiniFASNet.py
â”œâ”€ uploads/
â”‚  â”œâ”€ enroll/                  # saved enrollment shots
â”‚  â””â”€ proofs/                  # saved verification images
â”œâ”€ database/
â”‚  â””â”€ embeddings_db.npy        # user embeddings DB
â””â”€ .env.example                # example environment overrides
```

---

## âœ… Prerequisites
- **Python** 3.10â€“3.11 (recommended)
- **OS**: Windows / Linux / macOS
- **Optional GPU**: CUDA + `onnxruntime-gpu` (matching CUDA/cuDNN)

**Ubuntu system deps (example):**
```bash
sudo apt-get update
sudo apt-get install -y python3-dev build-essential libgl1
```

---

## ðŸš€ Setup

### 1) Create & activate a virtual environment
```bash
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# Windows (PowerShell)
# .venv\Scripts\Activate.ps1
```

### 2) Install Python packages
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 3) (Recommended) Track large model files with Git LFS
```bash
git lfs install
git lfs track "models/*.pt" "models/*.pth"
git add .gitattributes
git commit -m "chore: track model binaries with LFS"
```

### 4) Configure environment (optional)
Copy `.env.example` â†’ `.env` and adjust as needed.

```dotenv
# .env
ENV=dev
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:3000
EMBEDDING_THRESHOLD=0.55
LIVENESS_THRESHOLD=0.80
INSIGHT_PACK=buffalo_l
YOLO_MODEL_PATH=models/best.pt
LIVENESS_MODEL_PTH=models/2.7_80x80_MiniFASNetV2.pth
DET_W=416
DET_H=416
MAX_CONTENT_LENGTH_MB=8
```

> **Tip:** If you switch `INSIGHT_PACK` (e.g., `buffalo_l` â†” `antelopev2`), **reâ€‘enroll all users** to avoid drift in embeddings.

---

## â–¶ï¸ Run (Development)
From inside the virtual environment:
```bash
flask --app app.py run
# or
python app.py
```
Open: **http://127.0.0.1:5000/** for the built-in test page.

---

## ðŸ”§ Configuration Reference (`config.py`)
| Variable | Default | Meaning |
|---|---|---|
| `ENV` | `production` | nonâ€‘prod enables debug runner in `app.py` |
| `CORS_ORIGINS` | *(empty)* | commaâ€‘separated list of allowed frontâ€‘end origins |
| `MAX_CONTENT_LENGTH_MB` | `8` | request size cap in MB |
| `INSIGHT_PACK` | `buffalo_l` | InsightFace model pack (`buffalo_l` or `antelopev2`) |
| `DET_W`, `DET_H` | `416` | detector input size (smaller â†’ faster CPU) |
| `EMBEDDING_THRESHOLD` | `0.55` | face similarity threshold (cosine 0..1) |
| `LIVENESS_ENABLED` | `true` | toggle liveness check |
| `LIVENESS_THRESHOLD` | `0.80` | probability threshold for â€œrealâ€ |
| `LIVENESS_IMG_SIZE` | `80` | MiniFASNetV2 input size |
| `LIVENESS_NUM_CLASSES` | `3` | num classes used by the model |
| `REAL_CLASS_INDEX` | `2` | index of â€œrealâ€ class |
| `YOLO_MODEL_PATH` | `models/best.pt` | YOLO model path (pt/onnx) |
| `LIVENESS_MODEL_PTH` | `models/2.7_80x80_MiniFASNetV2.pth` | liveness model path |

---

## ðŸ§  How It Works (High Level)
1. **Enrollment** (`/api/signup`): Accepts 1â€“5 images for a username. Deduplicates frames by MD5, extracts face embeddings with InsightFace, stores **perâ€‘user centroid** and raw shots.
2. **Verification** (`/api/verify`): Given a username, task label, and proof image:
   - **Face match**: cosine similarity vs. stored centroid.
   - **Liveness**: MiniFASNetV2 classifies crop as real/spoof; thresholds decide pass/fail.
   - **Task detection**: YOLO detects required activity class via **alias mapping** (see `TASK_ALIASES`).
   - All three run **in parallel**; final status is approved only if **all pass**.

---

## ðŸŒ API Reference
**Base path:** `/api`

### Health
```http
GET /api/health
```
**200**
```json
{ "ok": true }
```

### Signup / Enrollment
> **Recommended**: send multiple shots via `images[]` (3â€“5 diverse angles). A single `image` is accepted as fallback.

```http
POST /api/signup
Content-Type: multipart/form-data
Form-Data:
  username: string
  images[]: file (repeat 3â€“5x)  # preferred
  image:    file                 # optional single-shot
```
**200**
```json
{ "status": true, "message": "User enrolled. shots=3" }
```
**4xx** on validation/face errors.

**Notes**
- Duplicate frames (exact bytes) are de-duplicated via **MD5**.
- Service keeps up to **5 most recent shots** per user and stores a **centroid embedding**.

### Verify Task
Runs **face match + liveness + YOLO** concurrently.

```http
POST /api/verify
Content-Type: multipart/form-data
Form-Data:
  username: string
  task: "plantation" | "waste collection" | "feeding animal"
  file: image
```
**200 (approved)**
```json
{
  "status":"approved",
  "user":"ritesh",
  "task":"plantation",
  "similarity": 0.71,
  "liveness_score": 0.99,
  "timestamp": "2025-08-10T17:16:47.546803Z"
}
```
**200 (rejected examples)**
```json
{ "status":"rejected","reason":"Face mismatch","similarity": 0.59 }
{ "status":"rejected","reason":"Liveness failed","liveness_score": 0.01 }
{ "status":"rejected","reason":"Task not verified" }
```

**Task label aliases** (edit in `modules/task_detection.py::TASK_ALIASES`):
- `"plantation"` â†’ `person_planting`, `people_planting`, `planting`
- `"waste collection"` â†’ `person-collecting-waste`, â€¦
- `"feeding animal"` â†’ `person_feeding_animal`, â€¦

---

## ðŸ§ª Quick cURL
```bash
# Enroll (single image)
curl -F "username=ritesh" -F "image=@/path/to/shot1.jpg" http://127.0.0.1:5000/api/signup

# Enroll (multi-shot)
curl -F "username=ritesh" \
     -F "images[]=@/path/shot1.jpg" \
     -F "images[]=@/path/shot2.jpg" \
     -F "images[]=@/path/shot3.jpg" \
     http://127.0.0.1:5000/api/signup

# Verify
curl -F "username=ritesh" -F "task=plantation" -F "file=@/path/proof.jpg" \
     http://127.0.0.1:5000/api/verify
```

---

## ðŸ“ˆ Performance Tips
- **CPU only**: keep `DET_W/H` at **320â€“416** for faster face detection; use YOLO `imgsz=512` (already set) or lower if needed.
- **GPU**: install `onnxruntime-gpu` with matching **CUDA/cuDNN**; the app will autoâ€‘select CUDA provider.
- **Throughput**: run behind **gunicorn/uvicorn + gevent/uvloop** in prod; put **Nginx** in front for TLS & static.
- **Queues**: for high QPS or bursty loads, consider **Celery/RQ** and persistent model worker processes.

---

## ðŸ” Security & Production Notes
- This repo includes a simple **test page**; **disable it** in production if your frontâ€‘end handles UX.
- Set **CORS** to the exact frontâ€‘end origin, e.g. `CORS_ORIGINS=https://your-frontend-domain`.
- Put behind a reverse proxy with **HTTPS** (Nginx/Traefik).
- Persist `database/embeddings_db.npy` to a **durable volume** (bind mount or cloud disk).
- Treat model files as assets: **Git LFS** or fetch from **object storage** during deploy.
- **Biometrics compliance**: storing embeddings and liveness results may be regulated; consult local laws and add consent/retention policies.

---

## ðŸ§° Troubleshooting
**Face mismatch is low (~0.58)**
- Enroll **3â€“5** diverse shots; ensure **good lighting**; include **frontal and slight angles**.
- **Reâ€‘enroll** users if switching `INSIGHT_PACK`.

**Liveness always fails**
- Confirm `REAL_CLASS_INDEX` with a temporary debug helper to inspect perâ€‘class probs.
- Check the **face crop** quality (poor detections â†’ poor liveness).

**YOLO not detecting**
- Verify `YOLO_MODEL_PATH` and label names in `TASK_ALIASES`.
- Try `imgsz=640` for tiny images (note: **slower** on CPU).

**ONNX â€œCUDAExecutionProvider not availableâ€**
- Youâ€™re on CPU. Install `onnxruntime-gpu` and matching **CUDA** to use the GPU.

---

## ðŸ§ª Test Page
- Navigate to `/` to use the builtâ€‘in **webcam**/**file upload** UI.
- For production, lock it behind auth or remove the route entirely.

---

## ðŸ§± Implementation Notes
- **Atomic writes**: `modules/dbio.py` writes `.npy` via tempâ€‘file + `os.replace` to avoid partial writes under concurrent access.
- **Unified errors**: `modules/errors.py` centralizes error responses (consistent JSON shape, HTTP codes).
- **Enrollment logic**: `modules/face_enroll.py` dedupes frames, extracts embeddings, updates centroid & shot set.
- **Verification logic**: `modules/face_verify.py` computes cosine similarity against centroid, supports multiâ€‘shot matching.
- **Liveness**: `modules/liveness_check.py` runs MiniFASNetV2; thresholds set in `config.py`.
- **Task detection**: `modules/task_detection.py` loads YOLO and checks **alias â†’ class** match for a pass.

---

## ðŸ§ª Postman Collection (optional)
You can quickly test by importing two requests:
- **Signup**: `POST /api/signup` (multipart form)
- **Verify**: `POST /api/verify` (multipart form)

---

## ðŸ“¦ Deployment (Example)
**Gunicorn (WSGI) + Nginx**
```bash
pip install gunicorn gevent
gunicorn -k gevent -w 2 -b 0.0.0.0:5000 app:app
```
- Terminate TLS and serve static via **Nginx**; forward `/api/*` to Gunicorn.
- Persist `database/` and `uploads/` via volumes.

**Docker (sketch)**
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
ENV PORT=5000
EXPOSE 5000
CMD ["python", "app.py"]
```

---

## ðŸ“œ License
**AGPL-3.0** â€” If you modify the service and offer it to users over a network, you **must** provide the source code of your modified version under the same license. See `LICENSE`.

---

## ðŸ™ Credits
- **InsightFace** (face detection/recognition)
- **SilentFace / MiniFASNet** (liveness)
- **Ultralytics YOLO** (task detection)

---

## ðŸ§­ Maintainers
-> Team-Z(Ashutosh)
